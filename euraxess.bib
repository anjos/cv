%%%%%%%%%%%%
%%  2019  %%
%%%%%%%%%%%%

@article{compbiomed-2020,
	title = {Competitive neural layer-based method to identify people with high risk for diabetic foot},
	volume = {120},
	url = {http://www.sciencedirect.com/science/article/pii/S0010482520301244},
    pdf = {https://www.idiap.ch/~aanjos/papers/compbiomed-2020.pdf},
	doi = {10.1016/j.compbiomed.2020.103744},
	abstract = {Background and objective: To automatically identify patients with diabetes mellitus (DM) who have high risk of developing diabetic foot, via an unsupervised machine learning technique.  Methods: We collected a new database containing 54 known risk factors from 250 patients diagnosed with diabetes mellitus. The database also contained a separate validation cohort composed of 73 subjects, where the perceived risk was annotated by expert nurses. A competitive neuron layer-based method was used to automatically split training data into two risk groups.  Results: We found that one of the groups was composed of patients with higher risk of developing diabetic foot. The dominant variables that described group membership via our method agreed with the findings from other studies, and indicated a greater risk for developing such a condition. Our method was validated on the available test data, reaching 71\% sensitivity, 100\% specificity, and 90\% accuracy.  Conclusions Unsupervised learning may be deployed to screen patients with diabetes mellitus, pointing out high-risk individuals who require priority follow-up in the prevention of diabetic foot with very high accuracy. The proposed method is automatic and does not require clinical examinations to perform risk assessment, being solely based on the information of a questionnaire answered by patients. Our study found that discriminant variables for predicting risk group membership are highly correlated with expert opinion.},
	journal = {Computers in Biology and Medicine},
	author = {Ferreira, Ana Cl\'audia Barbosa Hon\'orio and Ferreira, Danton Diego and Oliveira, Henrique Ceretta and Resende, Igor Carvalho de and Anjos, Andr\'e and Lopes, Maria Helena Baena de Moraes},
	month = may,
	year = {2020},
	keywords = {Artificial neural network, Diabetes mellitus, Diabetic foot},
}

@misc{arxiv-2019,
   title         = {On the Evaluation and Real-World Usage Scenarios of Deep Vessel Segmentation for Retinography},
   author        = {Tim Laibacher and Andr\'e Anjos},
   year          = {2019},
   month         = 9,
   eprint        = {1909.03856},
   archivePrefix = {arXiv},
   primaryClass  = {cs.CV},
   url           = {https://arxiv.org/abs/1909.03856},
   pdf           = {https://arxiv.org/pdf/1909.03856},
   abstract = {We identify and address three research gaps in the field of vessel segmentation for retinography.  The first focuses on the task of inference on high-resolution fundus images for which only a limited set of ground-truth data is publicly available.  Notably, we highlight that simple rescaling and padding or cropping of lower resolution datasets is surprisingly effective.  We further explore the effectiveness of semi-supervised learning for better domain adaptation in this context.  Our results show competitive performance on a set of common public retina datasets, using a small and light-weight neural network.  For HRF, the only very high-resolution dataset currently available, we reach comparable, if not superior, state-of-the-art performance by solely relying on training images from lower-resolution datasets.  The second topic we address concerns the lack of standardisation in evaluation metrics.  We investigate the variability of the F1-score on the existing datasets and report results for recently published architectures.  Our evaluation show that most reported results are actually comparable to each other in performance.  Finally, we address the issue of reproducibility, by open-sourcing the complete framework used to produce results shown here.},
}

@article{tifs-2019-2,
    author = {George, Anjith and Mostaani, Zohreh and Geissenbuhler, David and Nikisins, Olegs and Anjos, Andr{\'{e}} and Marcel, S{\'{e}}bastien},
    title = {Biometric Face Presentation Attack Detection with Multi-Channel Convolutional Neural Network},
    journal = {IEEE Transactions on Information Forensics and Security},
    month = 5,
    year = {2019},
    doi = {10.1109/TIFS.2019.2916652},
    pdf = {https://www.idiap.ch/~aanjos/papers/tifs-2019-2.pdf},
    abstract = {Face recognition is a mainstream biometric authentication method. However, vulnerability to presentation attacks (a.k.a spoofing) limits its usability in unsupervised applications. Even though there are many methods available for tackling presentation attacks (PA), most of them fail to detect sophisticated attacks such as silicone masks.
                As the quality of presentation attack instruments improves over time, achieving reliable PA detection with visual spectra alone remains very challenging. We argue that analysis in multiple channels might help to address this issue.  In this context, we propose a multi-channel Convolutional Neural Network based approach for presentation attack detection (PAD).
                We also introduce the new Wide Multi-Channel presentation Attack (WMCA) database for face PAD which contains a wide variety of 2D and 3D presentation attacks for both impersonation and obfuscation attacks. Data from different channels such as color, depth, near-infrared and thermal are available to advance the research in face PAD. The proposed method was compared with feature-based approaches and found to outperform the baselines achieving an ACER of 0.3\% on the introduced dataset. The database and the software to reproduce the results are made available publicly.},
}

@article{tifs-2019,
  author = {de Freitas Pereira, Tiago and Anjos, André and Marcel, Sébastien},
  month = 12,
  title = {Heterogeneous Face Recognition Using Domain Specific Units},
  journal = {IEEE Transactions on Information Forensics and Security},
  year = {2019},
  doi = {10.1109/TIFS.2018.2885284},
  url = "http://publications.idiap.ch/index.php/publications/show/3963",
  pdf = "https://www.idiap.ch/~aanjos/papers/ieee-tifs-2018.pdf",
  abstract = {The task of Heterogeneous Face Recognition consists in matching face images that are sensed in different domains, such as sketches to photographs (visual spectra images), thermal images to photographs or near-infrared images to photographs. In this work we suggest that high level features of Deep Convolutional Neural Networks trained on visual spectra images are potentially domain independent and can be used to encode faces sensed in different image domains. A generic framework for Heterogeneous Face Recognition is proposed by adapting Deep Convolutional Neural Networks low level features in, so called, “Domain Specific Units”. The adaptation using Domain Specific Units allow the learning of shallow feature detectors specific for each new image domain.  Furthermore, it handles its transformation to a generic face space shared between all image domains. Experiments carried out with four different face databases covering three different image domains show substantial improvements, in terms of recognition rate, surpassing the state-of-the-art for most of them. This work is made reproducible: all the source code, scores and trained models of this approach are made publicly available.},
}

@inproceedings{icml-2017-2,
  author = "Anjos, André and Günther, Manuel and de Freitas Pereira, Tiago and Korshunov, Pavel and Mohammadi, Amir and Marcel, Sébastien",
  month = 8,
  title = "Continuously Reproducing Toolchains in Pattern Recognition and Machine Learning Experiments",
  booktitle = "Thirty-fourth International Conference on Machine Learning",
  year = "2017",
  location = "Sidney, Australia",
  url = "https://publications.idiap.ch/index.php/publications/show/3666",
  pdf = "https://www.idiap.ch/~aanjos/papers/icml-2017-2.pdf",
  poster = "https://www.idiap.ch/~aanjos/posters/icml-2017-2.pdf",
  abstract = "Pattern recognition and machine learning research work often contains experimental results on real-world data, which corroborates hypotheses and provides a canvas for the development and comparison of new ideas. Results, in this context, are typically summarized as a set of tables and figures, allowing the comparison of various methods, highlighting the advantages of the proposed ideas. Unfortunately, result reproducibility is often an overlooked feature of original research publications, competitions, or benchmark evaluations. The main reason for such a gap is the complexity on the development of software associated with these reports. Software frameworks are difficult to install, maintain, and distribute, while scientific experiments often consist of many steps and parameters that are difficult to report. The increasingly rising complexity of research challenges make it even more difficult to reproduce experiments and results. In this paper, we emphasize that a reproducible research work should be repeatable, shareable, extensible, and stable, and discuss important lessons we learned in creating, distributing, and maintaining software and data for reproducible research in pattern recognition and machine learning. We focus on a specific use-case of face recognition and describe in details how we can make the recognition experiments reproducible in practice.",
}

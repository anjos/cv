\typeout{ ====================================================================}
\typeout{ This is file snsf-achievements, created at Mon 14 May 11:45:34 2018 CEST }
\typeout{ Andre Anjos <andre.anjos@idiap.ch>                                  }
\typeout{ ====================================================================}

\documentclass[a4paper,10pt,onecolumn]{article}
\usepackage[T1]{fontenc}

% Choose your font here - combinations with harmonized math symbols suggested
%\usepackage{lmodern} %Times-like
\usepackage{newpxtext} \usepackage[euler-digits]{eulervm} %Palatino-like
%\usepackage{libertine} \usepackage[libertine]{newtxmath} %Libertine-like

% sorting=none will preserve the bib file order
\usepackage[style=verbose-ibid,backend=biber,sorting=none,maxbibnames=3]{biblatex}
\addbibresource{publications.bib}

% adjust the page margins
\usepackage[scale=0.8]{geometry}

\usepackage{hyperref}
\usepackage{titling}

\pretitle{\vspace{-6em}\begin{flushleft}\LARGE}
\posttitle{\par\end{flushleft}}
\preauthor{}
\postauthor{}
\author{}
\predate{}
\postdate{}
\date{}

\hypersetup{
backref,%
colorlinks,%
citecolor=black,%
filecolor=black,%
linkcolor=black,%
urlcolor=black
}


\begin{document}

% In the section Major scientific achievements (max. 2 pages to be attached to
% the CV) the applicant describes his/her most important scientific
% achievements in the past five years.  Older achievements can be listed, if
% they are of particularly high importance for the proposal. In addition to
% scientific publications, any other relevant information, such as a knowledge
% transfer event, a software, database, prototype, etc. may be provided here.
% Describe for each achievement the applicant’s specific contribution and the
% overall impact of the work.

% All these items are intended for evaluators to specifically assess the
% scientific quality and relevance of the research output. If possible, the
% documents/sources of the various achievements should be made available to the
% evaluators via a direct open access web-link.

\title{Scientific Achievements (Dr. André Anjos)}
\maketitle

\section{Semantic Segmentation for Medical Imaging}

Since the introduction of U-Nets in 2015, the field of medical image
segmentation has seen renewed interest bringing in a variety of fully
convolutional (deep) neural network (FCN) architectures for binary and
multi-class segmentation problems promising very attractive results, with
applications in computed tomography, retinography, and histopathology to cite a
few.  Despite the incredible progress, the lack of annotated images (due to
cost), and rigor in the comparison of trained models has led the community to
believe larger and more dense networks provide better results.  This is
particularly noticeable in ophtalmological images such as those from
bi-dimensional eye fundus photography (retinography).  While retinography is
not used for precision diagnosis, it remains cheap and very effective means for
mass screening.  Semantical segmentation of eye fundus structures plays a key
role in this process.

I tried to address these gaps in two different ways.  The
first\footcite{arxiv-2019} was to conduct and publish rigorous (open source,
reproducible) benchmarks with popular retinography datasets and
state-of-the-art FCN models in which we: i) showed that simple transformation
techniques like rescaling, padding and cropping of combined lower-resolution
source datasets to the resolution and spatial composition of a
higher-resolution target dataset can be a surprisingly effective way to improve
segmentation quality in unseen conditions; ii) we proposed a set of plots and
metrics that give additional insights into model performance and demonstrated
via tables and plots how to take advantage of that information, throwing a new
light over some published benchmarks.  We argue the performance of many
contributions available in literature is actually quite comparable within
standard deviation margins of each other, in spite of huge differences in the
number of parameters for different architectures.  Finally, we made our
findings reproducible, distributing code and documentation for future
researchers to build upon, in the hopes to inspire future work in the
field\footnote{https://gitlab.idiap.ch/bob/bob.ip.binseg}.

In a second contribution\footcite{arxiv-2020} we propose that a minimalistic
version of a standard U-Net with 3 orders of magnitude less parameters,
carefully trained and rigorously evaluated, closely approximates the
state-of-the-art performance in vessel segmentation for retinography.  In
addition, we propose a simple extension, dubbed W-Net, by concatenating two
U-Nets together, which reaches outstanding performance on several popular
datasets, still using orders of magnitude less learnable weights than any
previously published approach.  This work also provide a very comprehensive
intra and cross-dataset performance analysis, involving up to 10 different
databases, including artery/vein multi-class semantic segmentation.

\section{Reproducible Research}

We've been actively looking at the reproducibility of published work and how to
lower the entrance barrier of publication readers, converting them into engaged
users of methods we create.  We argue it is insufficient, in most cases, to
only publish software leading to results if original data remains inaccessible.
In particular\footcite{icml-2017-2}, we note that reproducibility should imply
in the following characteristics: repeatability, shareability, extensibility
and stability, which is not guaranteed by most published material to date.  We
proposed a software suite called Bob (\url{https://www.idiap.ch/software/bob})
that possesses such characteristics, demonstrating its flexibility to various
tasks including Medical Image Segmentation
(\url{https://gitlab.idiap.ch/bob/bob.ip.binseg}), Remote Photoplethysmography
(\url{https://gitlab.idiap.ch/bob/bob.rppg.base}), and Biometric Person
Recognition (\url{https://gitlab.idiap.ch/bob/bob.bio.base}).  All
contributions are distributed under an open-source license.

From another perspective, there are legitimate cases in which raw data leading
to research conclusions cannot be published.  Furthermore, in a growing number
of use-cases, the availability of both software does not translate to an
accessible reproducibility scenario.  The user, for example, may not have the
necessary equipment to perform the analysis.  To bridge this gap, we built an
open platform for research\footnote{\url{https://www.beat-eu.org/platform}} in
computational sciences related to pattern recognition and machine learning, to
help on the development, reproducibility and certification of results obtained
in the field\footcite{icml-2017-1}.  The BEAT platform is distributed under an
open-source license\footnote{\url{https://www.idiap.ch/software/beat/}}.

Both projects are still active and support past and future work at Idiap and
beyond.  We conducted (and will continue doing) lectures to both master and
graduate students about reproducibility in data science (refer to the
applicant's CV under the section "Teaching" for details).  There are currently
$\sim$180 \textit{direct} citations to publications about Bob and BEAT core
frameworks.

\section{Biometric Recognition}

We advanced the state-of-the-art in presentation attack detection (PAD) through
various contributions, ranging from the exploration of different methods to
address PAD and assess biometric recognition vulnerabilities, to publishing
articles and book chapters, datasets and software for easy reproducibility of
claimed results.  Whilst not directly related to the proposal at hand, various
elements in this work may be re-used in the proposed research direction, and I
therefore report them here.

My contributions to biometric anti-spoofing can be summarized as follows:

\begin{itemize}

  \item Anomaly Detection and Robustness: Most PAD systems work
      discriminatively, trying to separate attacks from \textit{bona fide}
      presentations.  We showed this technique does not generalize well to
      unseen presentation attacks.  We explored, for the first time, alternate
      approaches by joint-modelling client identity as a way to calibrate PAD
      output scores\footcite{tifs-2015}, showing increased robustness to unseen
      attacks.  More recently, we also showed that solely modelling
      \textit{bona fide} presentations is also an effective way to increased
      PAD robustness\footcite{icb-2018}.

  \item Vulnerability Analysis and Evaluation: We demonstrated candidate
      presentation attack instruments and biometric recognition systems must
      undergo a vulnerability assessment to quantify the pertinence and quality
      of attacks\footcite{tifs-2014}.  We also devised a way to tune protected
      biometric systems to various different applications, with changing
      security requirements.

  \item Visual and Multi-spectral PAD: Finally, we showed it is possible to add
      sensors to PAD systems to improve their robustness\footcite{tifs-2019-2}.

\end{itemize}

This work was published as book chapters, international peer-reviewed
scientific journals (including articles at IEEE Transactions on Information
Forensics and Security with an impact factor of 4.3) and in peer-reviewed
conference papers totalling a few thousand citations.  Accompanying software
packages for such contributions were released publicly, under an open-source
license. For details and more links, please refer to the applicant's Research
Output.

\end{document}

\typeout{ *************** End of file cv *************** }
